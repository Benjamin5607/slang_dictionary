import os
import random
from flask import Flask, request, jsonify, send_file
import requests
from bs4 import BeautifulSoup
import urllib.parse

app = Flask(__name__)

# ---------------------------------------------------------
# ğŸ­ ì¸ê°„ ì½”ìŠ¤í”„ë ˆ í—¤ë” (User-Agent)
# ---------------------------------------------------------
def get_random_header():
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0"
    ]
    return {
        'User-Agent': random.choice(user_agents),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://www.google.com/'
    }

@app.route('/')
def home():
    try:
        return send_file('index.html')
    except:
        return "index.html íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ---------------------------------------------------------
# â›ï¸ í•µì‹¬ ì—”ì§„: DuckDuckGo Lite íŒŒì„œ
# ---------------------------------------------------------
def scrape_duckduckgo(term, country_code):
    """
    ë„¤ì´ë²„/êµ¬ê¸€ ëŒ€ì‹  ì°¨ë‹¨ì´ ëœí•œ 'DuckDuckGo Lite' ë²„ì „ì„ ê¸ìŠµë‹ˆë‹¤.
    """
    base_url = "https://lite.duckduckgo.com/lite/"
    
    # 1. ê²€ìƒ‰ì–´ ì „ëµ (Search Strategy)
    # í•œêµ­ì´ë©´ 'ë‚˜ë¬´ìœ„í‚¤' ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì°¾ë„ë¡ ìœ ë„
    if country_code == 'KR':
        # "ì¤‘êº¾ë§ˆ site:namu.wiki" í˜•íƒœë¡œ ê²€ìƒ‰ -> ë‚˜ë¬´ìœ„í‚¤ ë‚´ìš©ë§Œ ì™ ë½‘ì•„ì˜´
        query = f'site:namu.wiki "{term}"'
    elif country_code == 'JP':
        query = f'{term} ã¨ã¯ ã‚¹ãƒ©ãƒ³ã‚°'
    else:
        query = f'{term} slang meaning'

    payload = {
        'q': query,
        'kl': 'wt-wt' # ì§€ì—­ ì œí•œ í•´ì œ (ë” ë§ì€ ê²°ê³¼)
    }
    
    print(f"ğŸ•µï¸ Searching DDG: {query}") # ë¡œê·¸ í™•ì¸ìš©

    try:
        # íƒ€ì„ì•„ì›ƒ 10ì´ˆë¡œ ë„‰ë„‰í•˜ê²Œ
        res = requests.post(base_url, data=payload, headers=get_random_header(), timeout=10)
        
        # HTML íŒŒì‹±
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # DuckDuckGo Liteì˜ ê²°ê³¼ëŠ” í…Œì´ë¸” êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŒ
        # table 3ë²ˆì§¸êº¼ì˜ trë“¤ì„ ê°€ì ¸ì™€ì•¼ í•¨
        results = []
        tables = soup.find_all('table')
        
        if len(tables) < 3:
            print("âŒ DDG êµ¬ì¡° ë³€ê²½ë¨ or ì°¨ë‹¨ë¨")
            return []

        rows = tables[2].find_all('tr')
        
        current_title = None
        current_link = None

        for row in rows:
            # 1. ì œëª© ì¤„ (Title)
            link_tag = row.select_one('.result-link')
            if link_tag:
                current_title = link_tag.get_text(strip=True)
                current_link = link_tag['href']
                continue # ë‹¤ìŒ ì¤„ë¡œ (ë‹¤ìŒ ì¤„ì´ ìš”ì•½ë¬¸ì„)
            
            # 2. ìš”ì•½ ì¤„ (Snippet)
            snippet_tag = row.select_one('.result-snippet')
            if snippet_tag and current_title:
                clean_snippet = snippet_tag.get_text(strip=True)
                
                # ë‚˜ë¬´ìœ„í‚¤ ê²°ê³¼ë¼ë©´ ì œëª©ì—ì„œ ' - ë‚˜ë¬´ìœ„í‚¤' ê°™ì€ê±° ë–¼ê¸°
                clean_title = current_title.replace(" - ë‚˜ë¬´ìœ„í‚¤", "").replace(" - NamuWiki", "")

                results.append({
                    'word': clean_title,
                    'definition': clean_snippet,
                    'example': current_link,
                    'thumbs_up': 'NamuWiki' if country_code == 'KR' else 'Web Search'
                })
                
                # ì´ˆê¸°í™”
                current_title = None
                
                if len(results) >= 5: break

        return results

    except Exception as e:
        print(f"âŒ DDG Error: {e}")
        return []

# ---------------------------------------------------------
# ğŸš€ API ë¼ìš°íŠ¸
# ---------------------------------------------------------
@app.route('/scrape')
def scrape():
    term = request.args.get('term')
    country = request.args.get('country')
    
    if not term: return jsonify({'error': 'No term'})

    print(f"ğŸš€ Request: {country} - {term}")
    data_list = []

    # 1. ì˜ë¯¸ê¶Œ (API ì‚¬ìš© - ê°€ì¥ ë¹ ë¦„)
    if country in ['US', 'GB', 'AU', 'CA']:
        try:
            res = requests.get(f"https://api.urbandictionary.com/v0/define?term={term}", timeout=5)
            data_list = res.json().get('list', [])
        except:
            pass # ì‹¤íŒ¨í•˜ë©´ ì•„ë˜ DDGë¡œ ë„˜ì–´ê°

    # 2. ê·¸ ì™¸ ëª¨ë“  êµ­ê°€ (í•œêµ­ í¬í•¨) -> DuckDuckGoë¡œ í†µí•© ì²˜ë¦¬
    if not data_list:
        data_list = scrape_duckduckgo(term, country)

    # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´? 
    # í”„ë¡ íŠ¸ì—”ë“œì—ê²Œ "ê²°ê³¼ ì—†ìŒ"ì„ ëª…í™•íˆ ì „ë‹¬
    if not data_list:
        print("ğŸ˜¥ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨. ê²°ê³¼ 0ê°œ.")
    
    return jsonify({'mode': 'SCRAPE', 'list': data_list})

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 8080))
    app.run(host='0.0.0.0', port=port)
