import os
from flask import Flask, request, jsonify, send_file
import requests
from bs4 import BeautifulSoup
import urllib.parse

app = Flask(__name__)

# êµ­ê°€ë³„ DuckDuckGo ì§€ì—­ ì½”ë“œ ë§¤í•‘
DDG_REGIONS = {
    'CN': 'cn-zh', 'VN': 'vn-vi', 'TH': 'th-en', 'ID': 'id-id', # ì•„ì‹œì•„
    'FR': 'fr-fr', 'DE': 'de-de', 'ES': 'es-es', 'RU': 'ru-ru', # ìœ ëŸ½
    'BR': 'br-pt', 'MX': 'mx-es', 'SA': 'xa-ar'                 # ê¸°íƒ€
}

@app.route('/')
def home():
    return send_file('index.html')

def scrape_ddg(term, country_code):
    """ë•ë•ê³  ë¼ì´íŠ¸ ë²„ì „ì„ í¬ë¡¤ë§í•˜ëŠ” ë§ŒëŠ¥ í•¨ìˆ˜"""
    region = DDG_REGIONS.get(country_code, 'wt-wt') # ì—†ìœ¼ë©´ ì „ì„¸ê³„(wt-wt)
    # ê²€ìƒ‰ì–´ì— 'slang meaning'ì„ ë¶™ì—¬ì„œ ê²€ìƒ‰ ì •í™•ë„ ë†’ì„
    query = f"{term} slang meaning"
    
    url = "https://lite.duckduckgo.com/lite/"
    payload = {'q': query, 'kl': region}
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    results = []
    try:
        res = requests.post(url, data=payload, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë•ë•ê³  Liteì˜ ê²°ê³¼ í…Œì´ë¸” íŒŒì‹±
        rows = soup.select('table:nth-of-type(3) tr')
        
        current_title = ""
        for row in rows:
            # ì œëª© ì¤„ (ë§í¬)
            link_tag = row.select_one('.result-link')
            if link_tag:
                current_title = link_tag.get_text(strip=True)
                current_link = link_tag['href']
                continue
            
            # ìš”ì•½ ì¤„ (Snippet)
            snippet_tag = row.select_one('.result-snippet')
            if snippet_tag and current_title:
                results.append({
                    'word': current_title, # ê²€ìƒ‰ ê²°ê³¼ ì œëª©
                    'definition': snippet_tag.get_text(strip=True), # ìš”ì•½ ë‚´ìš©
                    'example': current_link, # ë§í¬
                    'thumbs_up': 'DuckDuckGo'
                })
                current_title = "" # ì´ˆê¸°í™”
                
                if len(results) >= 5: # 5ê°œë§Œ ìˆ˜ì§‘
                    break
    except Exception as e:
        print(f"DDG Error: {e}")
        
    return results

@app.route('/scrape')
def scrape():
    term = request.args.get('term')
    country = request.args.get('country')
    
    if not term:
        return jsonify({'error': 'No term'})

    print(f"â›ï¸ Mining: {country} - {term}")
    data_list = []

    try:
        # 1. ğŸ‡°ğŸ‡· í•œêµ­ (ë„¤ì´ë²„)
        if country == 'KR':
            url = f"https://dict.naver.com/search.dict?dicQuery={urllib.parse.quote(term)}&query={urllib.parse.quote(term)}&target=dict&ie=utf8&query_utf=&isOnlyViewEE="
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            items = soup.select('.dic_search_result .search_list li')
            for item in items[:4]:
                word_elem = item.select_one('dt > a')
                mean_elem = item.select_one('dd')
                if word_elem and mean_elem:
                    data_list.append({
                        'word': word_elem.get_text(strip=True),
                        'definition': mean_elem.get_text(strip=True),
                        'example': "https://dict.naver.com/" + word_elem['href'],
                        'thumbs_up': 'Naver'
                    })

        # 2. ğŸ‡¯ğŸ‡µ ì¼ë³¸ (Weblio)
        elif country == 'JP':
            url = f"https://www.weblio.jp/content/{urllib.parse.quote(term)}"
            res = requests.get(url)
            soup = BeautifulSoup(res.text, 'html.parser')
            title = soup.select_one('.midashigo')
            desc = soup.select_one('.kiji')
            if title and desc:
                data_list.append({
                    'word': title.get_text(strip=True),
                    'definition': desc.get_text(strip=True)[:200] + "...",
                    'example': url,
                    'thumbs_up': 'Weblio'
                })

        # 3. ğŸ‡ºğŸ‡¸ ì˜ë¯¸ê¶Œ (Urban Dictionary API)
        elif country in ['US', 'GB', 'AU', 'CA']:
            res = requests.get(f"https://api.urbandictionary.com/v0/define?term={term}")
            data_list = res.json().get('list', [])

        # 4. ğŸŒ ê·¸ ì™¸ ëª¨ë“  êµ­ê°€ (DuckDuckGo ë§ŒëŠ¥í‚¤)
        else:
            data_list = scrape_ddg(term, country)

    except Exception as e:
        return jsonify({'error': str(e)})

    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í”„ë¡ íŠ¸ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return jsonify({'mode': 'SCRAPE', 'list': data_list})

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 8080))
    app.run(host='0.0.0.0', port=port)
