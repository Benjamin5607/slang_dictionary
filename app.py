from flask import Flask, request, jsonify, send_file
import requests
from bs4 import BeautifulSoup
import urllib.parse

app = Flask(__name__)

# 1. ë©”ì¸ í™”ë©´ ë³´ì—¬ì£¼ê¸°
@app.route('/')
def home():
    return send_file('index.html')

# 2. í¬ë¡¤ë§ API (í•µì‹¬!)
@app.route('/scrape')
def scrape():
    term = request.args.get('term')
    country = request.args.get('country')
    
    if not term:
        return jsonify({'error': 'ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.'})

    print(f"â›ï¸ ì±„êµ´ ì‹œì‘: {country} - {term}")
    
    data_list = []

    # ----------------------------------
    # ğŸ‡°ğŸ‡· í•œêµ­: ë„¤ì´ë²„ ì˜¤í”ˆì‚¬ì „ í¬ë¡¤ë§
    # ----------------------------------
    if country == 'KR':
        # ë„¤ì´ë²„ ì˜¤í”ˆì‚¬ì „ ê²€ìƒ‰ URL
        url = f"https://dict.naver.com/search.dict?dicQuery={urllib.parse.quote(term)}&query={urllib.parse.quote(term)}&target=dict&ie=utf8&query_utf=&isOnlyViewEE="
        
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ 'ë‹¨ì–´'ì™€ 'ëœ»' ì°¾ê¸° (ë„¤ì´ë²„ HTML êµ¬ì¡° ë¶„ì„)
            # dic_search_result ì˜ì—­ ì•ˆì˜ ë°ì´í„° ì¶”ì¶œ
            results = soup.select('.dic_search_result .search_list li')
            
            for item in results[:5]: # ìƒìœ„ 5ê°œë§Œ
                try:
                    # ë‹¨ì–´ (dt > a)
                    word_elem = item.select_one('dt > a')
                    word = word_elem.get_text(strip=True) if word_elem else term
                    
                    # ëœ» (dd)
                    mean_elem = item.select_one('dd')
                    meaning = mean_elem.get_text(strip=True) if mean_elem else "ëœ»ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    
                    # ë§í¬
                    link = "https://dict.naver.com/" + word_elem['href'] if word_elem else "#"

                    data_list.append({
                        'word': word,
                        'definition': meaning,
                        'example': link, # ì˜ˆë¬¸ ëŒ€ì‹  ë§í¬ ì €ì¥
                        'thumbs_up': 'Naver'
                    })
                except:
                    continue
                    
        except Exception as e:
            print(f"KR Error: {e}")

    # ----------------------------------
    # ğŸ‡¯ğŸ‡µ ì¼ë³¸: Weblio ì‚¬ì „ (ì†ì–´/ì‹ ì¡°ì–´)
    # ----------------------------------
    elif country == 'JP':
        url = f"https://www.weblio.jp/content/{urllib.parse.quote(term)}"
        try:
            res = requests.get(url)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # Weblio êµ¬ì¡° ì¶”ì¶œ
            title = soup.select_one('.midashigo')
            desc = soup.select_one('.kiji')
            
            if title and desc:
                clean_desc = desc.get_text(strip=True)[:200] + "..." # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
                data_list.append({
                    'word': title.get_text(strip=True),
                    'definition': clean_desc,
                    'example': url,
                    'thumbs_up': 'Weblio'
                })
        except Exception as e:
             print(f"JP Error: {e}")

    # ----------------------------------
    # ğŸ‡ºğŸ‡¸ ì˜ë¯¸ê¶Œ: Urban Dictionary API (ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    # ----------------------------------
    else: 
        # ì´ê±´ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜ ì—¬ê¸°ì„œ í˜¸ì¶œí•´ë„ ë¨.
        # í¸ì˜ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë¦¬í„´í•˜ê³  í”„ë¡ íŠ¸ì—”ë“œê°€ API ë¶€ë¥´ê²Œ ë‘ 
        pass 

    return jsonify({'list': data_list})

if __name__ == '__main__':
    # 8080 í¬íŠ¸ì—ì„œ ì‹¤í–‰
    app.run(host='0.0.0.0', port=8080)
