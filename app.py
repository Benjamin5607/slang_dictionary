from flask import Flask, request, jsonify, send_file
import requests
from bs4 import BeautifulSoup
import urllib.parse

app = Flask(__name__)

@app.route('/')
def home():
    return send_file('index.html')

@app.route('/scrape')
def scrape():
    term = request.args.get('term')
    country = request.args.get('country') # KR, JP, US, VN, FR ...
    
    if not term:
        return jsonify({'error': 'No search term provided'})

    print(f"â›ï¸ ìš”ì²­ êµ­ê°€: {country} / ê²€ìƒ‰ì–´: {term}")
    
    data_list = []
    mode = "SCRAPE" # ê¸°ë³¸ ëª¨ë“œ: ê¸ì–´ì˜¤ê¸°

    try:
        # ----------------------------------
        # 1. ğŸ‡°ğŸ‡· í•œêµ­ (ë„¤ì´ë²„ ì˜¤í”ˆì‚¬ì „)
        # ----------------------------------
        if country == 'KR':
            url = f"https://dict.naver.com/search.dict?dicQuery={urllib.parse.quote(term)}&query={urllib.parse.quote(term)}&target=dict&ie=utf8&query_utf=&isOnlyViewEE="
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            results = soup.select('.dic_search_result .search_list li')
            
            for item in results[:3]:
                word_elem = item.select_one('dt > a')
                word = word_elem.get_text(strip=True) if word_elem else term
                mean_elem = item.select_one('dd')
                meaning = mean_elem.get_text(strip=True) if mean_elem else ""
                link = "https://dict.naver.com/" + word_elem['href'] if word_elem else "#"
                
                data_list.append({
                    'word': word,
                    'definition': meaning,
                    'example': link,
                    'thumbs_up': 'Naver'
                })

        # ----------------------------------
        # 2. ğŸ‡¯ğŸ‡µ ì¼ë³¸ (Weblio)
        # ----------------------------------
        elif country == 'JP':
            url = f"https://www.weblio.jp/content/{urllib.parse.quote(term)}"
            res = requests.get(url)
            soup = BeautifulSoup(res.text, 'html.parser')
            title = soup.select_one('.midashigo')
            desc = soup.select_one('.kiji')
            
            if title and desc:
                data_list.append({
                    'word': title.get_text(strip=True),
                    'definition': desc.get_text(strip=True)[:150] + "...",
                    'example': url,
                    'thumbs_up': 'Weblio'
                })

        # ----------------------------------
        # 3. ğŸ‡ºğŸ‡¸ ì˜ë¯¸ê¶Œ (Urban Dictionary API)
        # ----------------------------------
        elif country in ['US', 'GB', 'AU', 'CA', 'NZ', 'Global']:
            # íŒŒì´ì¬ ì„œë²„ê°€ ëŒ€ì‹  APIë¥¼ í˜¸ì¶œí•´ì¤Œ (CORS ë¬¸ì œ í•´ê²°)
            res = requests.get(f"https://api.urbandictionary.com/v0/define?term={term}")
            json_data = res.json()
            data_list = json_data.get('list', [])

        # ----------------------------------
        # 4. ê·¸ ì™¸ êµ­ê°€ (ì•„ì§ ì±„êµ´ê¸° ì—†ìŒ -> ë§í¬ ëª¨ë“œ)
        # ----------------------------------
        else:
            mode = "LINK" # í”„ë¡ íŠ¸ì—”ë“œì—ê²Œ "ë§í¬ ë²„íŠ¼ ë„ì›Œì¤˜"ë¼ê³  ì‹ í˜¸ ë³´ëƒ„
            
    except Exception as e:
        print(f"Server Error: {e}")
        return jsonify({'error': str(e)})

    return jsonify({
        'mode': mode,
        'country': country,
        'list': data_list
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
